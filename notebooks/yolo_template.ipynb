{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bab0503f"
      },
      "source": [
        "<center>\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mfranzon/yolo-training-template/blob/main/notebooks/yolo_template.ipynb)   \n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jFpu15nn9TYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071f3219-783f-42d9-d32f-0a18a17be1ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install opencv-python -q\n",
        "!pip install matplotlib -q\n",
        "!pip install kagglehub -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import yaml\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    import cv2\n",
        "    IS_COLAB = False\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ],
      "metadata": {
        "id": "XcYdPAlt9iD0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset(dataset_handle):\n",
        "    \"\"\"Download the Kaggle dataset.\"\"\"\n",
        "    try:\n",
        "        path = kagglehub.dataset_download(dataset_handle)\n",
        "        logging.info(f\"Downloaded dataset to: {path}\")\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to download dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "def detect_dataset_structure(dataset_path):\n",
        "    \"\"\"Detect train/val/test images and labels paths in the dataset.\"\"\"\n",
        "    paths = {}\n",
        "    subdirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "    logging.info(f\"Detected subdirs in dataset: {subdirs}\")\n",
        "    splits = ['train', 'valid', 'test']\n",
        "    for split in splits:\n",
        "        key_split = 'val' if split == 'valid' else split\n",
        "        if split in subdirs:\n",
        "            split_dir = os.path.join(dataset_path, split)\n",
        "            images_dir = os.path.join(split_dir, 'images')\n",
        "            labels_dir = os.path.join(split_dir, 'labels')\n",
        "            if os.path.exists(images_dir):\n",
        "                paths[f'{key_split}_images'] = images_dir\n",
        "            if os.path.exists(labels_dir):\n",
        "                paths[f'{key_split}_labels'] = labels_dir\n",
        "    if not paths:\n",
        "        # Check one level deeper\n",
        "        for subdir in subdirs:\n",
        "            sub_path = os.path.join(dataset_path, subdir)\n",
        "            if os.path.isdir(sub_path):\n",
        "                inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
        "                logging.info(f\"Checking inner subdirs in {subdir}: {inner_subdirs}\")\n",
        "                for split in splits:\n",
        "                    key_split = 'val' if split == 'valid' else split\n",
        "                    if split in inner_subdirs:\n",
        "                        split_dir = os.path.join(sub_path, split)\n",
        "                        images_dir = os.path.join(split_dir, 'images')\n",
        "                        labels_dir = os.path.join(split_dir, 'labels')\n",
        "                        if os.path.exists(images_dir):\n",
        "                            paths[f'{key_split}_images'] = images_dir\n",
        "                        if os.path.exists(labels_dir):\n",
        "                            paths[f'{key_split}_labels'] = labels_dir\n",
        "                if paths:\n",
        "                    dataset_path = sub_path\n",
        "                    break\n",
        "        if not paths:\n",
        "            # Check two levels deeper\n",
        "            for subdir in subdirs:\n",
        "                sub_path = os.path.join(dataset_path, subdir)\n",
        "                if os.path.isdir(sub_path):\n",
        "                    inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
        "                    for inner_subdir in inner_subdirs:\n",
        "                        inner_path = os.path.join(sub_path, inner_subdir)\n",
        "                        if os.path.isdir(inner_path):\n",
        "                            deepest_subdirs = [d for d in os.listdir(inner_path) if os.path.isdir(os.path.join(inner_path, d))]\n",
        "                            logging.info(f\"Checking deepest subdirs in {inner_subdir}: {deepest_subdirs}\")\n",
        "                            for split in splits:\n",
        "                                key_split = 'val' if split == 'valid' else split\n",
        "                                if split in deepest_subdirs:\n",
        "                                    split_dir = os.path.join(inner_path, split)\n",
        "                                    images_dir = os.path.join(split_dir, 'images')\n",
        "                                    labels_dir = os.path.join(split_dir, 'labels')\n",
        "                                    if os.path.exists(images_dir):\n",
        "                                        paths[f'{key_split}_images'] = images_dir\n",
        "                                    if os.path.exists(labels_dir):\n",
        "                                        paths[f'{key_split}_labels'] = labels_dir\n",
        "                            if paths:\n",
        "                                dataset_path = inner_path\n",
        "                                break\n",
        "                    if paths:\n",
        "                        break\n",
        "    logging.info(f\"Detected paths: {paths}\")\n",
        "    return paths, dataset_path\n",
        "\n",
        "def create_yaml(dataset_path, paths, nc, names):\n",
        "    \"\"\"Create the data.yaml file for YOLO training.\"\"\"\n",
        "    data_yaml = {\n",
        "        \"path\": dataset_path,\n",
        "        \"train\": os.path.relpath(paths.get('train_images', ''), dataset_path) if 'train_images' in paths else '',\n",
        "        \"val\": os.path.relpath(paths.get('val_images', ''), dataset_path) if 'val_images' in paths else '',\n",
        "        \"test\": os.path.relpath(paths.get('test_images', ''), dataset_path) if 'test_images' in paths else '',\n",
        "        \"nc\": nc,\n",
        "        \"names\": names,\n",
        "    }\n",
        "    yaml_path = f\"{os.path.basename(dataset_path)}.yaml\"\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        yaml.dump(data_yaml, f)\n",
        "    logging.info(f\"Created YAML config at: {yaml_path}\")\n",
        "    return yaml_path\n",
        "\n",
        "def train_model(yaml_path, epochs, imgsz, batch, device, project, name):\n",
        "    \"\"\"Train the YOLO model.\"\"\"\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        batch=batch,\n",
        "        device=device,\n",
        "        project=project,\n",
        "        name=name,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "kFtYFAgG9liY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    \"\"\"Load the YOLO model from the specified path.\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "    logging.info(f\"Model loaded from {model_path}\")\n",
        "    return model\n",
        "\n",
        "def infer_image(model, image_path, conf_thresh=0.5, save_path=None):\n",
        "    \"\"\"Perform inference on a single image.\"\"\"\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    img = cv2.imread(image_path)\n",
        "    results = model(img, conf=conf_thresh)\n",
        "    annotated = results[0].plot()\n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, annotated)\n",
        "        logging.info(f\"Annotated image saved to {save_path}\")\n",
        "    else:\n",
        "        if IS_COLAB:\n",
        "            cv2_imshow(annotated)\n",
        "        else:\n",
        "            cv2.imshow(\"Inference\", annotated)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "def infer_video(model, video_path, conf_thresh=0.5, save_path=None):\n",
        "    \"\"\"Perform inference on a video file.\"\"\"\n",
        "    if not os.path.exists(video_path):\n",
        "        raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
        "    if save_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        results = model(frame, conf=conf_thresh)\n",
        "        annotated = results[0].plot()\n",
        "        if save_path:\n",
        "            out.write(annotated)\n",
        "        else:\n",
        "            if IS_COLAB:\n",
        "                cv2_imshow(annotated)\n",
        "            else:\n",
        "                cv2.imshow(\"Inference\", annotated)\n",
        "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                    break\n",
        "        frame_count += 1\n",
        "        if frame_count % 100 == 0:\n",
        "            logging.info(f\"Processed {frame_count} frames\")\n",
        "    cap.release()\n",
        "    if save_path:\n",
        "        out.release()\n",
        "        logging.info(f\"Annotated video saved to {save_path}\")\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def infer_webcam(model, conf_thresh=0.5):\n",
        "    \"\"\"Perform real-time inference on webcam feed.\"\"\"\n",
        "    if IS_COLAB:\n",
        "      raise ValueError(\"Webcam inference is not supported in Google Colab.\")\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(\"Cannot access webcam\")\n",
        "    logging.info(\"Starting webcam inference. Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        results = model(frame, conf=conf_thresh)\n",
        "        annotated = results[0].plot()\n",
        "        cv2.imshow(\"Webcam Inference\", annotated)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "7wp4lD1A9z7J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example regarding potholes\n",
        "\n",
        "dataset_handle = 'jocelyndumlao/multi-weather-pothole-detection-mwpd'  # Kaggle dataset handle\n",
        "nc = 1  # Number of classes\n",
        "names = ['Potholes']  # Class names\n",
        "epochs = 1  # Training epochs\n",
        "imgsz = 512  # Image size\n",
        "batch = 32  # Batch size\n",
        "device = '0'  # Device: '0' for GPU, 'cpu' for CPU\n",
        "project = 'runs/train'  # Project dir\n",
        "name = 'yolo_train'  # Experiment name\n",
        "\n"
      ],
      "metadata": {
        "id": "ZfyM9HWT98Iq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = download_dataset(dataset_handle)\n",
        "logging.info(f\"Dataset downloaded to: {dataset_path}\")\n",
        "paths, dataset_path = detect_dataset_structure(dataset_path)\n",
        "if not paths:\n",
        "    raise ValueError(\"No standard train/val/test structure found in dataset\")\n",
        "yaml_path = create_yaml(dataset_path, paths, nc, names)\n",
        "results = train_model(yaml_path, epochs, imgsz, batch, device, project, name)\n",
        "logging.info(\"Training completed successfully\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DiwGD1sI-DXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'runs/train/yolo_train/weights/best.pt'  # Path to trained model\n",
        "input_source = 'highway.mp4'  # 'path/to/image.jpg', 'path/to/video.mp4', or 'webcam'\n",
        "conf_thresh = 0.5  # Confidence threshold\n",
        "output_path = ''  # Optional: 'annotated.jpg' or 'annotated.mp4'"
      ],
      "metadata": {
        "id": "0_PgiU06A7bp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_path)\n",
        "input_lower = input_source.lower()\n",
        "if input_lower == 'webcam':\n",
        "    infer_webcam(model, conf_thresh)\n",
        "elif input_lower.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tiff')):\n",
        "    infer_image(model, input_source, conf_thresh, output_path)\n",
        "elif input_lower.endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n",
        "    infer_video(model, input_source, conf_thresh, output_path)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported input type. Use image/video path or 'webcam'\")\n",
        "logging.info(\"Inference completed successfully\")"
      ],
      "metadata": {
        "id": "UIC8nz1TBBXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}